/**
 * useChatEngine - AI å¯¹è¯æ ¸å¿ƒå¼•æ“
 * æå–è‡ª UnifiedChatViewï¼Œè´Ÿè´£ API è°ƒç”¨ã€å·¥å…·æ‰§è¡Œã€æ¶ˆæ¯é˜Ÿåˆ—å¤„ç†
 * æ”¯æŒ Thinking UI æ¨¡å¼ï¼ˆCursor é£æ ¼ï¼‰
 * æ”¯æŒæ™ºèƒ½æ¨¡å‹è·¯ç”±ï¼ˆè‡ªåŠ¨é€‰æ‹© Haiku/Sonnet/Opusï¼‰
 */
import { useCallback, useRef, useEffect } from "react";
import { createNamedLogger } from "../../../utils/logger";
import type { AIMode, Plan, ToolCallStatus, ThinkingUIData } from "../../../stores";
import { useAIStore } from "../../../stores";
import { useFileStore } from "../../../stores";
import { MODELS, TOOL_CAPABLE_MODELS } from "../ModelPicker";
import {
  THINKING_UI_SYSTEM_PROMPT,
  buildThinkingUserPrompt,
  parseThinkingOutput,
} from "../../../../core/ai/thinking-prompt";
import { ModelRouter } from "../../../../core/ai/model-router";
import type { ToolCallInfo } from "@shared/types/ai";
import { agentToolService } from "../../../services/agentToolService";
import { collectCodebaseContext, formatCodebaseContext } from "../../../services/indexService";
import { messageCompressor } from "../../../../core/ai/messageCompressor";

const log = createNamedLogger("ChatEngine");

// æ¨¡å‹ä¸Šä¸‹æ–‡çª—å£å¤§å°ï¼ˆtoken æ•°ï¼‰
const MODEL_CONTEXT_WINDOWS: Record<string, number> = {
  claude: 180000,
  codesuc: 180000, // å·²å¼ƒç”¨ï¼Œä¿ç•™å…¼å®¹
  gemini: 900000,
  deepseek: 120000,
  glm: 128000,
  gpt: 120000,
};

/** æ ¹æ®æ¨¡å‹åè·å–ä¸Šä¸‹æ–‡çª—å£å¤§å° */
function getContextWindow(model: string): number {
  for (const [prefix, limit] of Object.entries(MODEL_CONTEXT_WINDOWS)) {
    if (model.startsWith(prefix)) return limit;
  }
  return 100000;
}

// æ¨¡å¼å·¥å…·æƒé™æ˜ å°„ - å¯¹æ ‡ Cursor çš„æ¨¡å¼å·®å¼‚åŒ–è®¾è®¡
const MODE_TOOLS: Record<AIMode, string[]> = {
  chat: [
    "workspace_listDir",
    "workspace_readFile",
    "workspace_search",
    "codebase_semantic",
    "editor_getActiveFile",
    "git_status",
    "git_diff",
  ], // Ask: åªè¯» + è¯­ä¹‰æœç´¢
  plan: [
    "workspace_listDir",
    "workspace_readFile",
    "workspace_search",
    "codebase_semantic",
    "editor_getActiveFile",
    "git_status",
    "git_diff",
  ], // Plan: åªè¯»
  agent: [
    "workspace_listDir",
    "workspace_readFile",
    "workspace_writeFile",
    "workspace_search",
    "codebase_semantic",
    "editor_getActiveFile",
    "terminal_execute",
    "git_status",
    "git_diff",
  ], // Agent: å®Œæ•´
  debug: [
    "workspace_listDir",
    "workspace_readFile",
    "workspace_search",
    "codebase_semantic",
    "editor_getActiveFile",
    "terminal_execute",
    "git_status",
    "git_diff",
  ], // Debug: åªè¯»+æ‰§è¡Œ
};

// æ”¯æŒå›¾ç‰‡/è§†è§‰çš„æ¨¡å‹åˆ—è¡¨ï¼ˆClaude Vision API æ ¼å¼ï¼‰
const VISION_CAPABLE_MODELS = [
  "claude-opus-4-6",
  "claude-sonnet-4-5-20250929",
  "claude-haiku-4-5-20251001",
  "claude-opus-4-6",
  "claude-sonnet-4-5-20250929",
  "claude-haiku-4-5-20251001",
  // OpenAI ä¹Ÿæ”¯æŒï¼Œä½†æ ¼å¼ä¸åŒï¼Œæš‚ä¸å¤„ç†
];

// æ£€æµ‹æ˜¯å¦æ˜¯è¯¢é—®æ¨¡å‹èº«ä»½çš„é—®é¢˜
const isModelIdentityQuestion = (text: string): boolean => {
  const patterns = [
    /ä½ æ˜¯ä»€ä¹ˆæ¨¡å‹/i,
    /ä½ æ˜¯å“ªä¸ªæ¨¡å‹/i,
    /ä½ æ˜¯è°/i,
    /ä½ å«ä»€ä¹ˆ/i,
    /what model/i,
    /which model/i,
    /who are you/i,
    /ä½ çš„åå­—/i,
    /ä½ æ˜¯.*(?:AI|åŠ©æ‰‹|æ¨¡å‹)/i,
    /ä½¿ç”¨çš„.*æ¨¡å‹/i,
    /(?:å½“å‰|ç°åœ¨).*æ¨¡å‹/i,
    /æ¨¡å‹.*æ˜¯ä»€ä¹ˆ/i,
    /ä»€ä¹ˆ.*æ¨¡å‹/i,
  ];
  return patterns.some((p) => p.test(text));
};

// æ£€æµ‹æ¶ˆæ¯æ˜¯å¦åŒ…å«æ¨¡å‹èº«ä»½å£°æ˜ï¼ˆç”¨äºè¿‡æ»¤å†å²ï¼‰
const containsModelIdentity = (text: string): boolean => {
  const patterns = [
    /^(?:ä½ å¥½[ï¼!]?\s*)?æˆ‘æ˜¯\s*\**\s*(?:Claude|GPT|Gemini|DeepSeek|GLM|Qwen|é€šä¹‰|æ–‡å¿ƒ|æ˜Ÿç«|MindCode)/im,
    /^(?:Hi[,.]?\s*)?I(?:'m| am)\s*(?:Claude|GPT|Gemini|DeepSeek|GLM)/im,
    /æˆ‘æ˜¯.*(?:ç”±|å¼€å‘çš„).*(?:AI|åŠ©æ‰‹|æ¨¡å‹)/i,
    /I am an? AI (?:assistant|model)/i,
    /ğŸ“Š\s*\*\*æ¨¡å‹ä¿¡æ¯\*\*/, // æˆ‘ä»¬è¿½åŠ çš„æ¨¡å‹ä¿¡æ¯å—
  ];
  return patterns.some((p) => p.test(text));
};

// ç”Ÿæˆæ¨¡å‹èº«ä»½ä¿¡æ¯åç¼€
const getModelInfoSuffix = (modelId: string, modelName: string, provider: string): string => {
  // è·å–å®é™…è°ƒç”¨çš„åº•å±‚æ¨¡å‹ï¼ˆç”¨äºç‰¹ä»·æ¸ é“ç­‰ï¼‰
  const actualModelMap: Record<string, string> = {
    "codesuc-opus": "claude-opus-4-6",
    "codesuc-sonnet": "claude-sonnet-4-5-20250929",
    "codesuc-haiku": "claude-haiku-4-5-20251001",
  };
  const actualModel = actualModelMap[modelId] || modelId;
  const isProxy = actualModel !== modelId;

  return `\n\n---\nğŸ“Š **æ¨¡å‹ä¿¡æ¯**\n- æ˜¾ç¤ºåç§°: ${modelName}\n- å®é™…æ¨¡å‹: \`${actualModel}\`\n- æœåŠ¡å•†: ${provider}${isProxy ? "\n- æ¸ é“ç±»å‹: ç‰¹ä»·ä»£ç†" : ""}`;
};

interface ToolResult {
  success: boolean;
  data?: any;
  error?: string;
}

interface PendingConfirm {
  call: ToolCallStatus;
  resolve: (ok: boolean) => void;
}

interface ChatEngineOptions {
  onPendingConfirm: (confirm: PendingConfirm | null) => void;
}

export function useChatEngine(options: ChatEngineOptions) {
  const {
    mode,
    model,
    getCurrentConversation,
    addMessage,
    isLoading,
    setLoading,
    streamingText,
    setStreamingText,
    appendStreamingText,
    contexts,
    thinkingText,
    setThinkingText,
    appendThinkingText,
    isThinking,
    setIsThinking,
    updateLastMessage,
    updateLastMessageToolCall,
    setPlan,
    enqueueMessage,
    dequeueMessage,
    clearMessageQueue,
    messageQueue,
    // Thinking UI ç›¸å…³
    useThinkingUIMode,
    thinkingUIData,
    thinkingUIStartTime,
    setThinkingUIData,
    setThinkingUIStartTime,
    updateLastMessageThinkingUI,
    // å¯¹è¯åˆ‡æ¢ç›¸å…³
    activeConversationId,
    // æ™ºèƒ½æ¨¡å‹è·¯ç”±
    useSmartRouting,
    setLastRoutingDecision,
  } = useAIStore();
  const { workspaceRoot, getActiveFile } = useFileStore();

  // æ¨¡å‹è·¯ç”±å™¨å®ä¾‹
  const routerRef = useRef<ModelRouter | null>(null);
  if (!routerRef.current || routerRef.current["primaryModel"] !== model) {
    routerRef.current = new ModelRouter(model);
  }

  const stopStreamRef = useRef<(() => void) | null>(null);
  const abortRef = useRef(false);
  const lastConversationIdRef = useRef<string | null>(null);

  // ç›‘å¬å¯¹è¯åˆ‡æ¢ï¼Œè‡ªåŠ¨åœæ­¢å½“å‰æµå¼è¯·æ±‚
  useEffect(() => {
    if (
      lastConversationIdRef.current !== null &&
      lastConversationIdRef.current !== activeConversationId &&
      stopStreamRef.current
    ) {
      log.info("å¯¹è¯åˆ‡æ¢ï¼Œåœæ­¢å½“å‰æµå¼è¯·æ±‚");
      stopStreamRef.current();
      stopStreamRef.current = null;
      abortRef.current = true;
    }
    lastConversationIdRef.current = activeConversationId;
  }, [activeConversationId]);

  // Thinking æ ‡ç­¾è§£æçŠ¶æ€ï¼ˆä¼ ç»Ÿæ¨¡å¼ï¼‰
  const thinkingStateRef = useRef({ isInThinking: false, buffer: "" });

  // Thinking UI æµå¼è§£æçŠ¶æ€ï¼ˆæ–°æ¨¡å¼ï¼‰
  const thinkingUIBufferRef = useRef("");

  // å¤„ç†æµå¼ tokenï¼Œè§£æ <thinking> æ ‡ç­¾
  // æ ¸å¿ƒåŸåˆ™ï¼šå°½å¯èƒ½å¿«é€Ÿè¾“å‡ºå†…å®¹ï¼Œåªç¼“å†²å¯èƒ½æ˜¯æ ‡ç­¾çš„éƒ¨åˆ†
  const handleStreamToken = useCallback(
    (token: string) => {
      const state = thinkingStateRef.current;
      state.buffer += token;

      // è°ƒè¯•æ—¥å¿—
      log.debug(
        "ThinkingParser token:",
        JSON.stringify(token.slice(0, 50)),
        "isInThinking:",
        state.isInThinking,
        "bufferLen:",
        state.buffer.length,
      );

      // å¾ªç¯å¤„ç† buffer ç›´åˆ°æ— æ³•ç»§ç»­
      let processing = true;
      while (processing) {
        processing = false;

        if (!state.isInThinking) {
          // === æœªåœ¨æ€è€ƒæ¨¡å¼ ===
          const startIdx = state.buffer.indexOf("<thinking>");
          if (startIdx !== -1) {
            // æ‰¾åˆ°å®Œæ•´çš„å¼€å§‹æ ‡ç­¾
            log.debug("ThinkingParser >>> ENTER thinking mode");
            const before = state.buffer.slice(0, startIdx);
            if (before) appendStreamingText(before);
            state.isInThinking = true;
            setIsThinking(true);
            state.buffer = state.buffer.slice(startIdx + 10);
            processing = true;
          } else {
            // æ£€æŸ¥æ˜¯å¦æœ‰éƒ¨åˆ† <thinking> æ ‡ç­¾
            // åªéœ€è¦ä¿ç•™æœ€åå¯èƒ½æ˜¯æ ‡ç­¾å¼€å¤´çš„éƒ¨åˆ†
            const partialMatch = state.buffer.match(
              /<(?:t(?:h(?:i(?:n(?:k(?:i(?:n(?:g)?)?)?)?)?)?)?)?$/,
            );
            if (partialMatch) {
              // æœ‰éƒ¨åˆ†æ ‡ç­¾ï¼Œè¾“å‡ºå‰é¢çš„å®‰å…¨å†…å®¹
              const safeEnd = state.buffer.length - partialMatch[0].length;
              if (safeEnd > 0) {
                appendStreamingText(state.buffer.slice(0, safeEnd));
                state.buffer = state.buffer.slice(safeEnd);
              }
              // ç­‰å¾…æ›´å¤šæ•°æ®
            } else {
              // æ²¡æœ‰éƒ¨åˆ†æ ‡ç­¾ï¼Œå…¨éƒ¨è¾“å‡º
              appendStreamingText(state.buffer);
              state.buffer = "";
            }
          }
        } else {
          // === åœ¨æ€è€ƒæ¨¡å¼ä¸­ ===
          const endIdx = state.buffer.indexOf("</thinking>");
          if (endIdx !== -1) {
            // æ‰¾åˆ°å®Œæ•´çš„ç»“æŸæ ‡ç­¾
            log.debug("ThinkingParser <<< EXIT thinking mode, content length:", endIdx);
            const thinkContent = state.buffer.slice(0, endIdx);
            if (thinkContent) {
              log.debug("ThinkingParser appendThinkingText:", thinkContent.slice(0, 100));
              appendThinkingText(thinkContent);
            }
            state.isInThinking = false;
            setIsThinking(false);
            state.buffer = state.buffer.slice(endIdx + 11);
            processing = true;
          } else {
            // æ£€æŸ¥æ˜¯å¦æœ‰éƒ¨åˆ† </thinking> æ ‡ç­¾
            const partialMatch = state.buffer.match(
              /<(?:\/(?:t(?:h(?:i(?:n(?:k(?:i(?:n(?:g)?)?)?)?)?)?)?)?)?$/,
            );
            if (partialMatch) {
              // æœ‰éƒ¨åˆ†ç»“æŸæ ‡ç­¾ï¼Œè¾“å‡ºå‰é¢çš„æ€è€ƒå†…å®¹
              const safeEnd = state.buffer.length - partialMatch[0].length;
              if (safeEnd > 0) {
                log.debug(
                  "ThinkingParser streaming thinking (partial end):",
                  state.buffer.slice(0, safeEnd).slice(0, 50),
                );
                appendThinkingText(state.buffer.slice(0, safeEnd));
                state.buffer = state.buffer.slice(safeEnd);
              }
              // ç­‰å¾…æ›´å¤šæ•°æ®
            } else {
              // æ²¡æœ‰éƒ¨åˆ†æ ‡ç­¾ï¼Œå…¨éƒ¨è¾“å‡ºä¸ºæ€è€ƒå†…å®¹
              log.debug("ThinkingParser streaming thinking:", state.buffer.slice(0, 50));
              appendThinkingText(state.buffer);
              state.buffer = "";
            }
          }
        }
      }
    },
    [appendStreamingText, appendThinkingText, setIsThinking],
  );

  // é‡ç½®æ€è€ƒçŠ¶æ€
  const resetThinkingState = useCallback(() => {
    thinkingStateRef.current = { isInThinking: false, buffer: "" };
    setThinkingText("");
    setIsThinking(false);
  }, [setThinkingText, setIsThinking]);

  // ä»æ–‡æœ¬ä¸­ç§»é™¤ <thinking> æ ‡ç­¾åŠå…¶å†…å®¹
  const stripThinkingTags = useCallback((text: string): string => {
    return text.replace(/<thinking>[\s\S]*?<\/thinking>/g, "").trim();
  }, []);

  // === Thinking UI æ¨¡å¼ç›¸å…³ ===

  // å¤„ç† Thinking UI æµå¼ token
  const handleThinkingUIToken = useCallback(
    (token: string) => {
      thinkingUIBufferRef.current += token;
      const buffer = thinkingUIBufferRef.current;

      // å°è¯•å¢é‡è§£æ JSON
      try {
        const partialData: Partial<ThinkingUIData> = {
          ui: { title: "Thinkingâ€¦", mode: "thinking", model: "", language: "", time_ms: 0 },
          thought_summary: [],
          trace: [],
          final_answer: "",
        };

        // æ£€æµ‹ ui.mode
        const modeMatch = buffer.match(/"mode"\s*:\s*"(\w+)"/);
        if (modeMatch && partialData.ui) {
          partialData.ui.mode = modeMatch[1] as ThinkingUIData["ui"]["mode"];
          if (modeMatch[1] === "done") {
            partialData.ui.title = "Done";
          } else if (modeMatch[1] === "answering") {
            partialData.ui.title = "Answeringâ€¦";
          }
        }

        // æ£€æµ‹ ui.model
        const modelMatch = buffer.match(/"model"\s*:\s*"([^"]+)"/);
        if (modelMatch && partialData.ui) {
          partialData.ui.model = modelMatch[1];
        }

        // æ£€æµ‹ thought_summary æ•°ç»„
        const thoughtMatch = buffer.match(/"thought_summary"\s*:\s*\[([\s\S]*?)\]/);
        if (thoughtMatch) {
          try {
            partialData.thought_summary = JSON.parse(`[${thoughtMatch[1]}]`);
          } catch {}
        }

        // æ£€æµ‹ trace æ•°ç»„
        const traceMatch = buffer.match(/"trace"\s*:\s*\[([\s\S]*?)\]/);
        if (traceMatch) {
          try {
            partialData.trace = JSON.parse(`[${traceMatch[1]}]`);
          } catch {}
        }

        // æ£€æµ‹ final_answerï¼ˆå¯èƒ½ä¸å®Œæ•´ï¼‰
        const answerMatch = buffer.match(/"final_answer"\s*:\s*"((?:[^"\\]|\\.)*)(?:"|$)/);
        if (answerMatch) {
          partialData.final_answer = answerMatch[1]
            .replace(/\\n/g, "\n")
            .replace(/\\t/g, "\t")
            .replace(/\\"/g, '"')
            .replace(/\\\\/g, "\\");
        }

        setThinkingUIData(partialData);
      } catch {
        /* å¿½ç•¥è§£æé”™è¯¯ */
      }
    },
    [setThinkingUIData],
  );

  // å®Œæˆ Thinking UI è§£æ
  const finishThinkingUI = useCallback((): ThinkingUIData | null => {
    const buffer = thinkingUIBufferRef.current;
    const parsed = parseThinkingOutput(buffer);

    if (parsed) {
      // è®¾ç½®è€—æ—¶
      if (thinkingUIStartTime) {
        parsed.ui.time_ms = Date.now() - thinkingUIStartTime;
      }
      parsed.ui.mode = "done";
      setThinkingUIData(parsed);
      updateLastMessageThinkingUI(parsed);
      return parsed;
    }

    return null;
  }, [thinkingUIStartTime, setThinkingUIData, updateLastMessageThinkingUI]);

  // é‡ç½® Thinking UI çŠ¶æ€
  const resetThinkingUI = useCallback(() => {
    thinkingUIBufferRef.current = "";
    setThinkingUIData(null);
    setThinkingUIStartTime(null);
  }, [setThinkingUIData, setThinkingUIStartTime]);

  // è·¯å¾„è§£æ
  const _resolvePath = useCallback(
    (p: string) => {
      if (p?.match(/^[a-zA-Z]:[/\\]/) || p?.startsWith("/")) return p;
      return workspaceRoot ? `${workspaceRoot}/${p}`.replace(/\\/g, "/") : p;
    },
    [workspaceRoot],
  );

  // å·¥å…·æ‰§è¡Œ - ä½¿ç”¨ AgentToolServiceï¼ˆå®‰å…¨æ£€æŸ¥ + æ£€æŸ¥ç‚¹ + ç»“æœæˆªæ–­ + å®¡è®¡æ—¥å¿—ï¼‰
  useEffect(() => {
    agentToolService.setContext({
      workspaceRoot,
      getActiveFile: () => {
        const f = getActiveFile();
        return f ? { path: f.path, content: f.content } : null;
      },
    });
  }, [workspaceRoot, getActiveFile]);

  const executeTool = useCallback(
    async (name: string, args: Record<string, unknown>): Promise<ToolResult> => {
      return await agentToolService.execute(name, args);
    },
    [],
  );

  // å·¥å…·ç¡®è®¤ Promise
  const confirmTool = useCallback(
    (call: ToolCallStatus): Promise<boolean> => {
      return new Promise((resolve) => options.onPendingConfirm({ call, resolve }));
    },
    [options],
  );

  // è§£æè®¡åˆ’
  const parsePlan = useCallback((text: string): Plan | null => {
    const jsonMatch =
      text.match(/```json\s*([\s\S]*?)\s*```/) ||
      text.match(/\{[\s\S]*"title"[\s\S]*"tasks"[\s\S]*\}/);
    if (!jsonMatch) return null;
    try {
      const json = jsonMatch[1] || jsonMatch[0];
      const parsed = JSON.parse(json);
      return {
        id: Date.now().toString(),
        title: parsed.title || "å¼€å‘è®¡åˆ’",
        goal: parsed.goal || "",
        status: "draft",
        version: 1,
        assumptions: parsed.assumptions || [],
        risks: parsed.risks || [],
        milestones: (parsed.milestones || []).map((m: Record<string, string>, i: number) => ({
          id: m.id || `m${i}`,
          label: m.label || String(m),
          estimated: m.estimated || "",
          completed: false,
        })),
        tasks: (parsed.tasks || []).map((t: Record<string, string>, i: number) => ({
          id: t.id || `t${i}`,
          label: t.label || String(t),
          completed: false,
        })),
      };
    } catch {
      return null;
    }
  }, []);

  // ç”Ÿæˆç³»ç»Ÿæç¤ºè¯ - å¸¦å¯è§æ¨ç†åè®®
  const getSystemPrompt = useCallback(() => {
    const activeFile = getActiveFile();
    const modelInfo = MODELS.find((m) => m.id === model) || MODELS[0];

    // è·å–å®é™…æ¨¡å‹åç§°
    const actualModelMap: Record<string, string> = {
      "codesuc-opus": "claude-opus-4-6",
      "codesuc-sonnet": "claude-sonnet-4-5-20250929",
      "codesuc-haiku": "claude-haiku-4-5-20251001",
    };
    const _actualModel = actualModelMap[model] || model;

    // ä¸Šä¸‹æ–‡ä¿¡æ¯
    const context = workspaceRoot
      ? `[å·¥ä½œåŒº: ${workspaceRoot}${activeFile ? `, å½“å‰æ–‡ä»¶: ${activeFile.path}` : ""}]`
      : "[æœªæ‰“å¼€å·¥ä½œåŒº]";

    // èº«ä»½ä¿¡æ¯
    const identityNote = `(ä½ æ˜¯ ${modelInfo.name}ï¼Œç”± ${modelInfo.provider} å¼€å‘ã€‚ä»…åœ¨è¢«é—®åˆ°æ—¶æ‰è¯´æ˜èº«ä»½ã€‚)`;

    // å¯è§æ¨ç†åè®® - è®©æ¨¡å‹è¾“å‡ºæ€è€ƒè¿‡ç¨‹
    const thinkingProtocol = `
### å¯è§æ¨ç†åè®®
å›ç­”å‰ï¼Œç”¨ <thinking> æ ‡ç­¾å±•ç¤ºåˆ†æè¿‡ç¨‹ã€‚

**æ ¼å¼è¦æ±‚ï¼š**
- ä½¿ç”¨çŸ­å¥å’Œåˆ—è¡¨ï¼ˆä¸ç”¨ Markdown æ ‡é¢˜ï¼‰
- å†…å®¹ï¼šä¸Šä¸‹æ–‡åˆ†æã€è¾¹ç•Œæƒ…å†µã€æ–¹æ¡ˆè§„åˆ’
- ä¸è¦è¯´"è®©æˆ‘æ€è€ƒ"ï¼Œç›´æ¥å¼€å§‹

**ç¤ºä¾‹ï¼š**
<thinking>
- ç”¨æˆ·éœ€æ±‚ï¼šéªŒè¯é‚®ç®±çš„æ­£åˆ™è¡¨è¾¾å¼
- è¾¹ç•Œæƒ…å†µï¼šå­åŸŸåã€ç‰¹æ®Šå­—ç¬¦ã€TLDé•¿åº¦
- æ–¹æ¡ˆï¼šæä¾›æ ‡å‡†ç‰ˆå’Œä¸¥æ ¼ç‰ˆä¸¤ç§å®ç°
</thinking>

[æ­£å¼å›ç­”]
`;

    // å·¥å…·ä½¿ç”¨æŒ‡å—
    const toolGuide = workspaceRoot
      ? `
**å·¥å…·ä½¿ç”¨ç­–ç•¥ï¼š**
- é˜…è¯»é¡¹ç›®æ—¶ï¼šå…ˆ listDir äº†è§£ç»“æ„ï¼Œå†é€’å½’è¯»å–å…³é”®ç›®å½•ï¼ˆsrc/, core/, main/ï¼‰
- ç†è§£ä»£ç æ—¶ï¼šè¯»å–å…¥å£æ–‡ä»¶ã€é…ç½®æ–‡ä»¶ã€READMEã€ä¸»è¦æ¨¡å—
- æœç´¢ä»£ç æ—¶ï¼šç”¨ workspace_search å¿«é€Ÿå®šä½å…³é”®è¯
- å¤§æ–‡ä»¶ï¼šä½¿ç”¨ startLine/endLine å‚æ•°åˆ†æ®µè¯»å–
- æ¯æ¬¡å·¥å…·è°ƒç”¨ååˆ†æç»“æœï¼Œå†³å®šæ˜¯å¦éœ€è¦æ›´å¤šä¿¡æ¯`
      : "";

    // æ ¹æ®æ¨¡å¼è¿”å›ç³»ç»Ÿæç¤ºè¯
    switch (mode) {
      case "chat":
        return `ç¼–ç¨‹åŠ©æ‰‹ã€‚${context} ${identityNote}
${thinkingProtocol}
ç›´æ¥ç®€æ´å›ç­”ï¼Œä¸è‡ªæˆ‘ä»‹ç»ã€‚${toolGuide}`;

      case "plan":
        return `é¡¹ç›®æ¶æ„å¸ˆã€‚${context} ${identityNote}
${thinkingProtocol}
åˆ†æéœ€æ±‚ï¼Œè¾“å‡º JSON è®¡åˆ’ï¼š
\`\`\`json
{"title":"","goal":"","tasks":[{"id":"t1","label":"","files":[]}],"risks":[]}
\`\`\`
${toolGuide}`;

      case "agent": {
        // Agent æ¨¡å¼ï¼šè‡ªåŠ¨ç”Ÿæˆé¡¹ç›®ç»“æ„æ‘˜è¦
        let projectContext = "";
        if (workspaceRoot) {
          const wsName = workspaceRoot.split(/[/\\]/).pop() || "";
          projectContext = `
**é¡¹ç›®ä¿¡æ¯ï¼š**
- å·¥ä½œåŒºï¼š${wsName} (${workspaceRoot})
${activeFile ? `- å½“å‰æ–‡ä»¶ï¼š${activeFile.path}` : ""}

**æ‰§è¡Œç­–ç•¥ï¼ˆé‡è¦ï¼‰ï¼š**
1. å…ˆç”¨ workspace_listDir äº†è§£é¡¹ç›®ç»“æ„
2. è¯»å–å…³é”®æ–‡ä»¶ï¼špackage.json / README / å…¥å£æ–‡ä»¶
3. ç”¨ workspace_search ç²¾ç¡®å®šä½ç›¸å…³ä»£ç 
4. ä¿®æ”¹å‰å…ˆ readFile ç¡®è®¤å½“å‰å†…å®¹
5. å†™å…¥åéªŒè¯å˜æ›´æ­£ç¡®æ€§
6. æ¯æ­¥æ“ä½œéƒ½ç®€è¦è¯´æ˜æ„å›¾

**å®‰å…¨è§„åˆ™ï¼š**
- ä¿®æ”¹å‰è‡ªåŠ¨åˆ›å»ºæ£€æŸ¥ç‚¹ï¼ˆå¯å›æ»šï¼‰
- ç¦æ­¢ä¿®æ”¹ node_modules / .git / .env
- å¤§æ–‡ä»¶ä½¿ç”¨ startLine/endLine åˆ†æ®µè¯»å–`;
        }
        return `ä½ æ˜¯ MindCode è‡ªä¸»ç¼–ç¨‹ä»£ç†ã€‚${identityNote}
${thinkingProtocol}
${workspaceRoot ? `ä½ å¯ä»¥è¯»å†™æ–‡ä»¶ã€æœç´¢ä»£ç ã€æ‰§è¡Œç»ˆç«¯å‘½ä»¤ã€‚${projectContext}${toolGuide}` : "è¯·å…ˆæ‰“å¼€ä¸€ä¸ªå·¥ä½œåŒºæ–‡ä»¶å¤¹ã€‚"}`;
      }

      case "debug":
        return `è°ƒè¯•ä¸“å®¶ã€‚${context} ${identityNote}
${thinkingProtocol}
åˆ†æé”™è¯¯æ ¹å› ï¼Œç»™å‡ºä¿®å¤æ–¹æ¡ˆã€‚${workspaceRoot ? `å¯æŸ¥çœ‹æºç å’Œ git diffã€‚${toolGuide}` : ""}`;

      default:
        return `åŠ©æ‰‹ã€‚${context} ${identityNote}
${thinkingProtocol}`;
    }
  }, [mode, model, workspaceRoot, getActiveFile]);

  // è·å– Thinking UI æ¨¡å¼çš„ç³»ç»Ÿæç¤ºè¯ï¼ˆè¿”å›ä¸¥æ ¼ JSONï¼‰
  const getThinkingUISystemPrompt = useCallback(() => {
    return THINKING_UI_SYSTEM_PROMPT;
  }, []);

  // æ„å»º Thinking UI æ¨¡å¼çš„ç”¨æˆ·æ¶ˆæ¯
  const buildThinkingUIUserMessage = useCallback(
    (userRequest: string) => {
      const activeFile = getActiveFile();
      const modelInfo = MODELS.find((m) => m.id === model) || MODELS[0];

      return buildThinkingUserPrompt({
        model: modelInfo.name,
        language: activeFile?.path?.split(".").pop() || "unknown",
        userRequest,
        styleHints: "éµå¾ªé¡¹ç›®ä»£ç é£æ ¼",
        diagnostics: "",
        prefix: activeFile?.content?.slice(0, 2000) || "",
        suffix: "",
        relatedSnippets: "",
        toolResults: "",
      });
    },
    [model, getActiveFile],
  );

  // è·å–å·¥å…·å®šä¹‰ - æ ¹æ®æ¨¡å¼å’Œå·¥ä½œåŒºçŠ¶æ€è¿‡æ»¤å¯ç”¨å·¥å…·
  const getTools = useCallback(() => {
    // æ²¡æœ‰å·¥ä½œåŒºæ—¶ï¼Œä¸æä¾›æ–‡ä»¶ç³»ç»Ÿç›¸å…³çš„å·¥å…·
    if (!workspaceRoot) {
      log.info("æ— å·¥ä½œåŒºï¼Œä¸æä¾›å·¥å…·");
      return [];
    }

    const allTools = [
      {
        name: "workspace_listDir",
        description: "åˆ—å‡ºç›®å½•å†…å®¹ï¼Œäº†è§£é¡¹ç›®ç»“æ„",
        parameters: {
          type: "object" as const,
          properties: { path: { type: "string", description: "ç›®å½•è·¯å¾„" } },
          required: ["path"],
        },
      },
      {
        name: "workspace_readFile",
        description: "è¯»å–æ–‡ä»¶å†…å®¹ï¼Œæ”¯æŒæŒ‡å®šè¡ŒèŒƒå›´",
        parameters: {
          type: "object" as const,
          properties: {
            path: { type: "string", description: "æ–‡ä»¶è·¯å¾„" },
            startLine: { type: "number", description: "èµ·å§‹è¡Œ" },
            endLine: { type: "number", description: "ç»“æŸè¡Œ" },
          },
          required: ["path"],
        },
      },
      {
        name: "workspace_writeFile",
        description: "å†™å…¥æ–‡ä»¶ï¼ˆéœ€ç”¨æˆ·ç¡®è®¤ï¼‰",
        parameters: {
          type: "object" as const,
          properties: {
            path: { type: "string", description: "æ–‡ä»¶è·¯å¾„" },
            content: { type: "string", description: "æ–‡ä»¶å†…å®¹" },
          },
          required: ["path", "content"],
        },
      },
      {
        name: "workspace_search",
        description: "åœ¨é¡¹ç›®ä¸­æœç´¢ä»£ç ï¼ˆæ–‡æœ¬åŒ¹é…ï¼‰",
        parameters: {
          type: "object" as const,
          properties: {
            query: { type: "string", description: "æœç´¢å…³é”®è¯" },
            maxResults: { type: "number", description: "æœ€å¤§ç»“æœæ•°" },
          },
          required: ["query"],
        },
      },
      {
        name: "codebase_semantic",
        description: "è¯­ä¹‰æœç´¢ä»£ç åº“ï¼ˆ@codebaseï¼‰ï¼Œä½¿ç”¨å‘é‡åµŒå…¥æ‰¾åˆ°è¯­ä¹‰ç›¸å…³çš„ä»£ç ",
        parameters: {
          type: "object" as const,
          properties: {
            query: { type: "string", description: "è‡ªç„¶è¯­è¨€æŸ¥è¯¢" },
            topK: { type: "number", description: "è¿”å›ç»“æœæ•°" },
          },
          required: ["query"],
        },
      },
      {
        name: "editor_getActiveFile",
        description: "è·å–å½“å‰ç¼–è¾‘å™¨æ‰“å¼€çš„æ–‡ä»¶",
        parameters: { type: "object" as const, properties: {} },
      },
      {
        name: "terminal_execute",
        description: "æ‰§è¡Œç»ˆç«¯å‘½ä»¤ï¼ˆéœ€ç”¨æˆ·ç¡®è®¤ï¼‰",
        parameters: {
          type: "object" as const,
          properties: {
            command: { type: "string", description: "è¦æ‰§è¡Œçš„å‘½ä»¤" },
            cwd: { type: "string", description: "å·¥ä½œç›®å½•" },
          },
          required: ["command"],
        },
      },
      {
        name: "git_status",
        description: "è·å– Git çŠ¶æ€",
        parameters: { type: "object" as const, properties: {} },
      },
      {
        name: "git_diff",
        description: "è·å– Git å·®å¼‚",
        parameters: {
          type: "object" as const,
          properties: {
            path: { type: "string", description: "æ–‡ä»¶è·¯å¾„" },
            staged: { type: "boolean", description: "æ˜¯å¦æš‚å­˜åŒº" },
          },
          required: ["path"],
        },
      },
    ];
    // æ ¹æ®å½“å‰æ¨¡å¼è¿‡æ»¤å·¥å…·
    const allowedTools = MODE_TOOLS[mode] || [];
    return allTools.filter((t) => allowedTools.includes(t.name));
  }, [mode, workspaceRoot]);

  // å‘é€æ¶ˆæ¯æ ¸å¿ƒé€»è¾‘ï¼ˆæ”¯æŒå›¾ç‰‡ï¼‰
  const handleSend = useCallback(
    async (input: string, images?: import("../../../stores").ImageAttachment[]) => {
      if (!input.trim() && (!images || images.length === 0)) return;
      const userContent = input.trim();

      // æ£€æµ‹æ˜¯å¦æ˜¯è¯¢é—®æ¨¡å‹èº«ä»½çš„é—®é¢˜
      const askingModelIdentity = isModelIdentityQuestion(userContent);

      // å¦‚æœæ­£åœ¨åŠ è½½ä¸­ï¼Œå°†æ¶ˆæ¯åŠ å…¥é˜Ÿåˆ—ï¼ˆæš‚ä¸æ”¯æŒå›¾ç‰‡é˜Ÿåˆ—ï¼‰
      if (isLoading) {
        enqueueMessage(userContent, [...contexts], mode);
        return true; // è¿”å› true è¡¨ç¤ºå·²å…¥é˜Ÿ
      }

      let finalContent = userContent;
      if (contexts.length > 0) {
        finalContent =
          contexts
            .map((c) => `[${c.type}: ${c.label}]\n${c.data.content || c.data.path}`)
            .join("\n\n") + `\n\nç”¨æˆ·: ${userContent}`;
      }

      // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯ï¼ˆåŒ…å«å›¾ç‰‡ï¼‰
      addMessage({
        role: "user",
        content: userContent || "(å›¾ç‰‡)",
        mode,
        images: images && images.length > 0 ? images : undefined,
      });
      setLoading(true);
      setStreamingText("");
      abortRef.current = false;

      const conversation = getCurrentConversation();
      const messages = conversation?.messages || [];
      let systemPrompt = getSystemPrompt();
      const modelInfo = MODELS.find((m) => m.id === model) || MODELS[0];
      const tools = getTools();

      // @codebase ä¸Šä¸‹æ–‡æ³¨å…¥ â€” è‡ªåŠ¨æ”¶é›†ç›¸å…³ä»£ç 
      // åœ¨ Agent æ¨¡å¼ä¸‹å§‹ç»ˆæ³¨å…¥ï¼›åœ¨ Chat æ¨¡å¼ä¸‹å½“æ¶ˆæ¯åŒ…å« @codebase æ—¶æ³¨å…¥
      const shouldInjectContext = mode === "agent" || /(@codebase|@ä»£ç åº“)/i.test(userContent);
      if (shouldInjectContext && workspaceRoot) {
        try {
          const codebaseCtx = await collectCodebaseContext(userContent, {
            maxSnippets: 8,
            maxTokens: 6000,
          });
          if (codebaseCtx.snippets.length > 0) {
            const contextText = formatCodebaseContext(codebaseCtx);
            systemPrompt += `\n\n## ä»£ç åº“ä¸Šä¸‹æ–‡ï¼ˆ@codebase è‡ªåŠ¨æ”¶é›†ï¼Œå…± ${codebaseCtx.snippets.length} ä¸ªç›¸å…³ç‰‡æ®µï¼‰\n${contextText}`;
            log.info(
              `@codebase æ³¨å…¥ ${codebaseCtx.snippets.length} ä¸ªä»£ç ç‰‡æ®µ, ~${codebaseCtx.estimatedTokens} tokens`,
            );
          }
        } catch (e) {
          log.warn("@codebase ä¸Šä¸‹æ–‡æ”¶é›†å¤±è´¥:", e);
        }
      }

      // å…ˆæ£€æŸ¥æ˜¯å¦ä¼šä½¿ç”¨å·¥å…·ï¼ˆåŸºäºç”¨æˆ·é€‰æ‹©çš„ä¸»æ¨¡å‹ï¼‰
      const willUseTools = tools.length > 0 && TOOL_CAPABLE_MODELS.includes(model);

      // æ™ºèƒ½æ¨¡å‹è·¯ç”±ï¼šæ ¹æ®ä»»åŠ¡ç±»å‹è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ¨¡å‹
      // å…³é”®ï¼šå¦‚æœä¼šä½¿ç”¨å·¥å…·ï¼Œè¯´æ˜æ˜¯å¤æ‚ä»»åŠ¡ï¼Œåº”è¯¥ç”¨ä¸»æ¨¡å‹
      let effectiveModel = model;
      if (useSmartRouting && routerRef.current) {
        routerRef.current.setEnabled(true);
        routerRef.current.setPrimaryModel(model);
        const routingResult = routerRef.current.route(userContent, {
          isFirstRound: true,
          messageCount: messages.length,
          useTools: willUseTools, // ä¼ å…¥å·¥å…·ä½¿ç”¨ä¿¡æ¯
        });
        effectiveModel = routingResult.model;
        setLastRoutingDecision({
          model: routingResult.model,
          taskType: routingResult.taskType,
          reason: routingResult.reason,
        });
        if (effectiveModel !== model) {
          log.info(
            `æ™ºèƒ½è·¯ç”±: ${model} â†’ ${effectiveModel} (ä»»åŠ¡: ${routingResult.taskType}, ä½¿ç”¨å·¥å…·: ${willUseTools})`,
          );
        }
      }

      // è°ƒè¯•æ—¥å¿—
      log.debug(
        "å‘é€æ¶ˆæ¯, ä¸»æ¨¡å‹:",
        model,
        ", å®é™…æ¨¡å‹:",
        effectiveModel,
        ", èº«ä»½é—®é¢˜:",
        askingModelIdentity,
        ", ä½¿ç”¨å·¥å…·:",
        willUseTools,
      );
      log.debug("ç³»ç»Ÿæç¤ºè¯å‰200å­—:", systemPrompt.slice(0, 200));

      // è¿‡æ»¤å¯¹è¯å†å²ä¸­æ¶‰åŠæ¨¡å‹èº«ä»½çš„å†…å®¹ï¼Œé˜²æ­¢èº«ä»½æ··æ·†
      // å½“ç”¨æˆ·è¯¢é—®èº«ä»½é—®é¢˜æ—¶ï¼Œè¿‡æ»¤æ‰æ‰€æœ‰èº«ä»½ç›¸å…³çš„é—®ç­”å¯¹
      const chatHistory = messages
        .filter((m) => m.role !== "system")
        .filter((m) => {
          // å¦‚æœå½“å‰é—®é¢˜æ˜¯èº«ä»½é—®é¢˜ï¼Œè¿‡æ»¤æ‰å†å²ä¸­æ‰€æœ‰èº«ä»½ç›¸å…³å†…å®¹
          if (askingModelIdentity) {
            // è¿‡æ»¤ç”¨æˆ·çš„èº«ä»½é—®é¢˜
            if (m.role === "user" && isModelIdentityQuestion(m.content)) {
              log.debug("è¿‡æ»¤èº«ä»½é—®é¢˜:", m.content.slice(0, 30) + "...");
              return false;
            }
            // è¿‡æ»¤ assistant çš„èº«ä»½å£°æ˜
            if (m.role === "assistant" && containsModelIdentity(m.content)) {
              log.debug("è¿‡æ»¤èº«ä»½å›ç­”:", m.content.slice(0, 50) + "...");
              return false;
            }
          } else {
            // éèº«ä»½é—®é¢˜æ—¶ï¼Œä»ç„¶è¿‡æ»¤æ‰ä»¥èº«ä»½å£°æ˜å¼€å¤´çš„æ¶ˆæ¯ï¼ˆé˜²æ­¢æ±¡æŸ“ï¼‰
            if (m.role === "assistant" && containsModelIdentity(m.content)) {
              log.debug("è¿‡æ»¤èº«ä»½æ¶ˆæ¯:", m.content.slice(0, 50) + "...");
              return false;
            }
          }
          return true;
        })
        .map((m) => ({ role: m.role as "user" | "assistant", content: m.content }));

      // ä¸Šä¸‹æ–‡çª—å£ç®¡ç†ï¼šè‡ªåŠ¨å‹ç¼©è¶…é•¿å†å²
      if (chatHistory.length > 0) {
        const systemTokens = messageCompressor.estimateTokens([
          { role: "system", content: systemPrompt },
        ]);
        const maxHistoryTokens = Math.floor(getContextWindow(effectiveModel) * 0.75) - systemTokens; // ç•™ 25% ç»™è¾“å‡º
        const compressed = messageCompressor.compress(
          chatHistory.map((m) => ({ ...m, role: m.role as "user" | "assistant" | "system" })),
          maxHistoryTokens,
        );
        if (compressed.tokensSaved > 0) {
          log.info(
            `å†å²å‹ç¼©: ${compressed.originalCount}â†’${compressed.compressedCount} æ¡, èŠ‚çœ ~${compressed.tokensSaved} tokens`,
          );
          chatHistory.splice(
            0,
            chatHistory.length,
            ...compressed.messages.map((m) => ({
              role: m.role as "user" | "assistant",
              content: m.content,
            })),
          );
        }
      }

      // æ„å»º API æ¶ˆæ¯ï¼Œæ”¯æŒå›¾ç‰‡ï¼ˆClaude Vision API æ ¼å¼ï¼‰
      type VisionBlock =
        | { type: "image"; source: { type: "base64"; media_type: string; data: string } }
        | { type: "text"; content: string };
      let userMessageContent: string | VisionBlock[] = finalContent;
      const supportsVision = VISION_CAPABLE_MODELS.includes(effectiveModel);

      if (images && images.length > 0) {
        if (!supportsVision) {
          // æ¨¡å‹ä¸æ”¯æŒå›¾ç‰‡ï¼Œæ·»åŠ æç¤ºä¿¡æ¯
          log.warn("å½“å‰æ¨¡å‹ä¸æ”¯æŒå›¾ç‰‡:", effectiveModel);
          userMessageContent = `[æ³¨æ„ï¼šå½“å‰æ¨¡å‹ ${effectiveModel} ä¸æ”¯æŒå›¾ç‰‡è¯†åˆ«ï¼Œå›¾ç‰‡å·²å¿½ç•¥]\n\n${finalContent}`;
        } else {
          // ä½¿ç”¨ Claude Vision API æ ¼å¼: content æ˜¯æ•°ç»„
          userMessageContent = [
            ...images.map((img) => ({
              type: "image" as const,
              source: {
                type: "base64" as const,
                media_type: img.mimeType,
                data: img.data.replace(/^data:image\/\w+;base64,/, ""), // ç§»é™¤ data URL å‰ç¼€
              },
            })),
            { type: "text" as const, content: finalContent || "è¯·æè¿°è¿™å¼ å›¾ç‰‡" },
          ];
        }
      }
      // Vision API çš„ content å¯ä»¥æ˜¯ string | VisionBlock[]ï¼Œä½† IPC å±‚ç»Ÿä¸€åºåˆ—åŒ–ï¼Œå®‰å…¨æ–­è¨€
      type APIMessage = {
        role: "system" | "user" | "assistant" | "tool";
        content: string;
        toolCalls?: ToolCallInfo[];
        toolCallId?: string;
      };
      const apiMessages: APIMessage[] = [
        { role: "system", content: systemPrompt },
        ...chatHistory,
        { role: "user", content: userMessageContent as string },
      ];

      // æ‰€æœ‰æ¨¡å¼éƒ½å¯ä»¥ä½¿ç”¨å·¥å…·ï¼ˆå·¥å…·å·²æŒ‰ MODE_TOOLS è¿‡æ»¤ï¼‰ï¼Œåªè¦æ¨¡å‹æ”¯æŒ
      // æ³¨æ„ï¼šè¿™é‡Œç”¨ effectiveModel æ£€æŸ¥ï¼Œå› ä¸ºè·¯ç”±åçš„æ¨¡å‹ä¹Ÿéœ€è¦æ”¯æŒå·¥å…·
      const useTools = willUseTools && TOOL_CAPABLE_MODELS.includes(effectiveModel);
      // åªæœ‰ Agent å’Œ Debug æ¨¡å¼ä¸‹çš„å±é™©æ“ä½œéœ€è¦ç¡®è®¤
      const requiresConfirm =
        mode === "agent" || mode === "debug" ? ["workspace_writeFile", "terminal_execute"] : [];
      log.debug("æ¨¡å¼:", mode, ", å¯ç”¨å·¥å…·æ•°:", tools.length, ", ä½¿ç”¨å·¥å…·:", useTools);

      let usedFallbackModel: string | null = null;

      // å®Œæˆåå¤„ç†é˜Ÿåˆ—çš„å‡½æ•°
      const processQueue = () => {
        const nextMsg = dequeueMessage();
        if (nextMsg) {
          setTimeout(() => {
            addMessage({ role: "user", content: nextMsg.content, mode: nextMsg.mode });
            setLoading(true);
            setStreamingText("");
            abortRef.current = false;

            const newSystemPrompt = getSystemPrompt();
            const currentConv = getCurrentConversation();
            // é˜Ÿåˆ—æ¶ˆæ¯ä¹Ÿéœ€è¦æ£€æµ‹æ˜¯å¦æ˜¯èº«ä»½é—®é¢˜
            const queueAskingIdentity = isModelIdentityQuestion(nextMsg.content);
            // è¿‡æ»¤å¯¹è¯å†å²ä¸­æ¶‰åŠæ¨¡å‹èº«ä»½çš„å†…å®¹
            const newChatHistory =
              currentConv?.messages
                .filter((m) => m.role !== "system")
                .filter((m) => {
                  if (queueAskingIdentity) {
                    if (m.role === "user" && isModelIdentityQuestion(m.content)) return false;
                    if (m.role === "assistant" && containsModelIdentity(m.content)) return false;
                  } else {
                    if (m.role === "assistant" && containsModelIdentity(m.content)) return false;
                  }
                  return true;
                })
                .map((m) => ({ role: m.role as "user" | "assistant", content: m.content })) || [];
            let queueFinalContent = nextMsg.content;
            if (nextMsg.contexts.length > 0) {
              queueFinalContent =
                nextMsg.contexts
                  .map((c) => `[${c.type}: ${c.label}]\n${c.data.content || c.data.path}`)
                  .join("\n\n") + `\n\nç”¨æˆ·: ${nextMsg.content}`;
            }
            const queueApiMessages: APIMessage[] = [
              { role: "system", content: newSystemPrompt },
              ...newChatHistory,
              { role: "user", content: queueFinalContent },
            ];

            addMessage({ role: "assistant", content: "", mode: nextMsg.mode });
            resetThinkingState();
            // é˜Ÿåˆ—æ¶ˆæ¯ä¹Ÿä½¿ç”¨æ™ºèƒ½è·¯ç”±åçš„æ¨¡å‹
            const cleanup = window.mindcode?.ai?.chatStream?.(effectiveModel, queueApiMessages, {
              onToken: (token: string) => handleStreamToken(token),
              onComplete: (fullText: string) => {
                const savedThinking = useAIStore.getState().thinkingText; // ä¿å­˜æ€è€ƒå†…å®¹
                updateLastMessage(
                  stripThinkingTags(fullText),
                  savedThinking ? { thinkingContent: savedThinking } : undefined,
                );
                setStreamingText("");
                resetThinkingState();
                setLoading(false);
                processQueue();
              },
              onError: (error: string) => {
                updateLastMessage(error);
                setStreamingText("");
                resetThinkingState();
                setLoading(false);
                processQueue();
              },
            });
            stopStreamRef.current = cleanup || null;
          }, 300);
        }
      };

      if (useTools) {
        if (!window.mindcode?.ai?.chatStreamWithTools) {
          updateLastMessage("é”™è¯¯: å½“å‰ç¯å¢ƒä¸æ”¯æŒå·¥å…·è°ƒç”¨ API");
          setLoading(false);
          processQueue();
          return false;
        }
        addMessage({ role: "assistant", content: "", mode });
        let iterations = 0;
        const maxIterations = 50; // å¢åŠ å·¥å…·å¾ªç¯ä¸Šé™

        while (iterations < maxIterations && !abortRef.current) {
          iterations++;
          log.debug(`å·¥å…·å¾ªç¯ #${iterations}/${maxIterations}, æ¶ˆæ¯æ•°: ${apiMessages.length}`);
          let responseText = "";
          let toolCalls: ToolCallInfo[] = [];
          try {
            await new Promise<void>((resolve, reject) => {
              if (!window.mindcode?.ai?.chatStreamWithTools) {
                reject(new Error("API ä¸å¯ç”¨"));
                return;
              }
              log.debug(
                "è°ƒç”¨ chatStreamWithTools, å·¥å…·æ•°:",
                tools.length,
                ", å·¥å…·å:",
                tools.map((t) => t.name).join(", "),
                ", æ¨¡å‹:",
                effectiveModel,
              );
              resetThinkingState();
              window.mindcode.ai.chatStreamWithTools(effectiveModel, apiMessages, tools, {
                onToken: (token) => {
                  responseText += token;
                  handleStreamToken(token);
                },
                onToolCall: (calls) => {
                  log.debug("æ”¶åˆ°å·¥å…·è°ƒç”¨:", calls);
                  toolCalls = calls;
                },
                onComplete: (_fullText, meta) => {
                  log.debug("chatStreamWithTools å®Œæˆ");
                  if (meta?.usedFallback) usedFallbackModel = meta.model;
                  resolve();
                },
                onError: (err) => {
                  log.error("chatStreamWithTools é”™è¯¯:", err);
                  reject(new Error(err));
                },
                onFallback: (from, to) => {
                  appendStreamingText(`\n\n> âš ï¸ ${from} æœåŠ¡ç¹å¿™ï¼Œå·²è‡ªåŠ¨åˆ‡æ¢åˆ° ${to}\n\n`);
                  usedFallbackModel = to;
                },
              });
            });
          } catch (e: unknown) {
            log.error("å·¥å…·è°ƒç”¨é”™è¯¯:", e);
            updateLastMessage(`é”™è¯¯: ${e instanceof Error ? e.message : "è¯·æ±‚å¤±è´¥"}`);
            break;
          }

          log.debug(
            `å·¥å…·è°ƒç”¨å®Œæˆ, å“åº”é•¿åº¦: ${responseText.length}, å·¥å…·è°ƒç”¨æ•°: ${toolCalls.length}`,
          );
          if (abortRef.current) break;
          if (toolCalls.length === 0) {
            let finalSuffix = usedFallbackModel ? `\n\n*å·²è‡ªåŠ¨åˆ‡æ¢åˆ° ${usedFallbackModel}*` : "";
            // å¦‚æœæ˜¯è¯¢é—®æ¨¡å‹èº«ä»½çš„é—®é¢˜ï¼Œè¿½åŠ å®é™…æ¨¡å‹ä¿¡æ¯
            if (askingModelIdentity) {
              finalSuffix += getModelInfoSuffix(model, modelInfo.name, modelInfo.provider);
            }
            // æ¸…ç† thinking æ ‡ç­¾åä¿å­˜ï¼Œä¿ç•™æ€è€ƒå†…å®¹
            const savedThinking = useAIStore.getState().thinkingText;
            updateLastMessage(
              stripThinkingTags(responseText) + finalSuffix,
              savedThinking ? { thinkingContent: savedThinking } : undefined,
            );
            resetThinkingState();
            break;
          }

          const calls: ToolCallStatus[] = toolCalls.map((tc) => ({
            id: tc.id,
            name: tc.name,
            args: tc.arguments,
            status: "pending" as const,
          }));
          // æ¸…ç† thinking æ ‡ç­¾å¹¶ä¿å­˜æ€è€ƒå†…å®¹
          const savedThinking = useAIStore.getState().thinkingText;
          const cleanedResponse = stripThinkingTags(responseText);
          updateLastMessage(cleanedResponse, {
            toolCalls: calls,
            ...(savedThinking ? { thinkingContent: savedThinking } : {}),
          });
          setStreamingText("");
          apiMessages.push({ role: "assistant", content: cleanedResponse, toolCalls });

          for (const call of calls) {
            if (abortRef.current) break;
            if (requiresConfirm.includes(call.name)) {
              const confirmed = await confirmTool(call);
              if (!confirmed) {
                updateLastMessageToolCall(call.id, { status: "failed", error: "ç”¨æˆ·å–æ¶ˆ" });
                apiMessages.push({
                  role: "tool",
                  toolCallId: call.id,
                  content: JSON.stringify({ error: "ç”¨æˆ·å–æ¶ˆ" }),
                });
                continue;
              }
            }
            updateLastMessageToolCall(call.id, { status: "running" });
            const result = await executeTool(call.name, call.args);
            updateLastMessageToolCall(call.id, {
              status: result.success ? "success" : "failed",
              result: result.data,
              error: result.error,
            });
            apiMessages.push({
              role: "tool",
              toolCallId: call.id,
              content: JSON.stringify(result.success ? result.data : { error: result.error }),
            });
          }
        }
        // å¦‚æœè¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œæç¤ºç”¨æˆ·
        if (iterations >= maxIterations) {
          const limitWarning = `\n\n> âš ï¸ å·¥å…·è°ƒç”¨å·²è¾¾ä¸Šé™ï¼ˆ${maxIterations}æ¬¡ï¼‰ï¼Œä»»åŠ¡å¯èƒ½æœªå®Œæˆã€‚è¯·ç»§ç»­å¯¹è¯è®©æˆ‘å®Œæˆå‰©ä½™å·¥ä½œã€‚`;
          appendStreamingText(limitWarning);
          const thinkingContent = useAIStore.getState().thinkingText;
          const currentContent = useAIStore.getState().streamingText || "";
          updateLastMessage(
            stripThinkingTags(currentContent),
            thinkingContent ? { thinkingContent } : undefined,
          );
        }
        setStreamingText("");
        setLoading(false);
        processQueue();
      } else if (useThinkingUIMode) {
        // === Thinking UI æ¨¡å¼ï¼šä½¿ç”¨ç»“æ„åŒ– JSON è¾“å‡º ===
        addMessage({ role: "assistant", content: "", mode });
        resetThinkingUI();
        setThinkingUIStartTime(Date.now());

        // ä½¿ç”¨ Thinking UI ä¸“ç”¨æç¤ºè¯
        const thinkingUIMessages = [
          { role: "system" as const, content: getThinkingUISystemPrompt() },
          ...chatHistory,
          { role: "user" as const, content: buildThinkingUIUserMessage(finalContent) },
        ];

        const cleanup = window.mindcode?.ai?.chatStream?.(effectiveModel, thinkingUIMessages, {
          onToken: (token: string) => handleThinkingUIToken(token),
          onComplete: (_fullText: string, meta?: { model: string; usedFallback: boolean }) => {
            const parsed = finishThinkingUI();
            if (parsed) {
              // Thinking UI æ¨¡å¼ä¸‹ï¼Œfinal_answer ä½œä¸ºæ¶ˆæ¯å†…å®¹
              let suffix = meta?.usedFallback ? `\n\n*å·²è‡ªåŠ¨åˆ‡æ¢åˆ° ${meta.model}*` : "";
              if (askingModelIdentity) {
                suffix += getModelInfoSuffix(model, modelInfo.name, modelInfo.provider);
              }
              updateLastMessage(parsed.final_answer + suffix, { thinkingUI: parsed });
            } else {
              // è§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬
              updateLastMessage(thinkingUIBufferRef.current);
            }
            resetThinkingUI();
            setLoading(false);
            stopStreamRef.current = null;
            processQueue();
          },
          onError: (error: string) => {
            updateLastMessage(error);
            resetThinkingUI();
            setLoading(false);
            stopStreamRef.current = null;
            processQueue();
          },
          onFallback: (from: string, to: string) => {
            log.info(`Thinking UI fallback: ${from} -> ${to}`);
          },
        });
        stopStreamRef.current = cleanup || null;
      } else {
        // === ä¼ ç»Ÿæ¨¡å¼ï¼šä½¿ç”¨ <thinking> æ ‡ç­¾ ===
        addMessage({ role: "assistant", content: "", mode });
        resetThinkingState();
        const cleanup = window.mindcode?.ai?.chatStream?.(effectiveModel, apiMessages, {
          onToken: (token: string) => handleStreamToken(token),
          onComplete: (fullText: string, meta?: { model: string; usedFallback: boolean }) => {
            // æ¸…ç† thinking æ ‡ç­¾åçš„æ–‡æœ¬
            const cleanedText = stripThinkingTags(fullText);
            const plan = mode === "plan" ? parsePlan(cleanedText) : null;
            let suffix = meta?.usedFallback ? `\n\n*å·²è‡ªåŠ¨åˆ‡æ¢åˆ° ${meta.model}*` : "";
            // å¦‚æœæ˜¯è¯¢é—®æ¨¡å‹èº«ä»½çš„é—®é¢˜ï¼Œè¿½åŠ å®é™…æ¨¡å‹ä¿¡æ¯
            if (askingModelIdentity) {
              suffix += getModelInfoSuffix(model, modelInfo.name, modelInfo.provider);
            }
            const savedThinking = useAIStore.getState().thinkingText; // ä¿å­˜æ€è€ƒå†…å®¹
            updateLastMessage(cleanedText + suffix, {
              ...(plan ? { plan } : {}),
              ...(savedThinking ? { thinkingContent: savedThinking } : {}),
            });
            if (plan) setPlan(plan);
            setStreamingText("");
            resetThinkingState();
            setLoading(false);
            stopStreamRef.current = null;
            processQueue();
          },
          onError: (error: string) => {
            updateLastMessage(error);
            setStreamingText("");
            resetThinkingState();
            setLoading(false);
            stopStreamRef.current = null;
            processQueue();
          },
          onFallback: (from: string, to: string) => {
            appendStreamingText(`\n\n> âš ï¸ ${from} æœåŠ¡ç¹å¿™ï¼Œå·²è‡ªåŠ¨åˆ‡æ¢åˆ° ${to}\n\n`);
          },
        });
        stopStreamRef.current = cleanup || null;
      }
      return false;
    },
    [
      model,
      mode,
      isLoading,
      contexts,
      getSystemPrompt,
      getTools,
      addMessage,
      setLoading,
      setStreamingText,
      appendStreamingText,
      updateLastMessage,
      updateLastMessageToolCall,
      executeTool,
      confirmTool,
      parsePlan,
      setPlan,
      enqueueMessage,
      dequeueMessage,
      getCurrentConversation,
      // Thinking UI ç›¸å…³ä¾èµ–
      useThinkingUIMode,
      handleThinkingUIToken,
      finishThinkingUI,
      resetThinkingUI,
      getThinkingUISystemPrompt,
      buildThinkingUIUserMessage,
      setThinkingUIStartTime,
    ],
  );

  // åœæ­¢ç”Ÿæˆ
  const handleStop = useCallback(() => {
    stopStreamRef.current?.();
    abortRef.current = true;
    if (streamingText) {
      updateLastMessage(streamingText + "\n\n[å·²åœæ­¢]");
    }
    setStreamingText("");
    setLoading(false);
  }, [streamingText, updateLastMessage, setStreamingText, setLoading]);

  return {
    handleSend,
    handleStop,
    isLoading,
    streamingText,
    thinkingText,
    isThinking,
    messageQueue,
    clearMessageQueue,
    // Thinking UI ç›¸å…³
    thinkingUIData,
    thinkingUIStartTime,
    useThinkingUIMode,
  };
}
